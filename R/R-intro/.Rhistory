plot_beta <- function(s1,s2) {
x <- rbeta(10000,s1,s2)
d <- density(x)
plot(d,col="blue", axes=FALSE, xlab = "", ylab = "", main = "")
polygon(d, col="green", border="green")
abline(v=mean(x),col="blue",lwd=5)
abline(v=median(x),col="red",lwd=5)
}
plot_beta(10,1)
plot_beta(10,10)
library(ggplot2)
library(latex2exp)
# poisson -----------------------------------------------------------------
par(mfrow=c(2,2))
hist(rpois(100,3),col="blue", xlab = "X", main = "Sample A")
hist(rpois(100,3),col="blue", xlab = "X", main = "Sample B")
hist(rpois(100,3),col="blue", xlab = "X", main = "Sample C")
hist(rpois(100,3),col="blue", xlab = "X", main = "Sample D")
dev.off()
# should make these probabilities
par(mfrow=c(2,2))
hist(replicate(10^1, mean(rpois(100,3))), col="orange", xlab = "mu", main = "10 Samples")
hist(replicate(10^2, mean(rpois(100,3))), col="orange", xlab = "mu", main = "100 Samples")
hist(replicate(10^3, mean(rpois(100,3))), col="orange", xlab = "mu", main = "1000 Samples")
hist(replicate(10^4, mean(rpois(100,3))), col="orange", xlab = "mu", main = "10000 Samples")
dev.off()
# diminishing marginal returns
true_mean <- 3
samples <- seq(1, 10000,1)
m_hat <- mapply(function(x) mean(rpois(x,true_mean))-true_mean,samples)
df <- data.frame(samples, m_hat)
cummean <- function(x) cumsum(x) / seq_along(x)
df$cum_m_hat <- cummean(df$m_hat)
p1 <- ggplot(df, aes(samples, m_hat)) + geom_line(color="blue") +
labs(x="Sample size", y=TeX('Bias ($\\mu - \\hat{\\mu}$)'), title=TeX('Population mean $\\mu = 3$')) +
scale_y_continuous(limits=c(-1, 1)) +
geom_hline(yintercept=0, color="red") +
theme_classic() +
scale_x_log10()
p2 <- ggplot(df, aes(samples, cum_m_hat)) +
geom_hline(yintercept=0, color="red", alpha=0.5) +
geom_line(color="orange") +
labs(x="Sample size", y='Average cumulative bias', title=TeX('Population mean $\\mu = 3$')) +
scale_y_continuous(limits=c(-1, 1)) +
theme_classic() +
scale_x_log10()
cowplot::plot_grid(p1,p2,ncol = 2, labels = "AUTO")
# uniform ---------------------------- -------------------------------------
par(mfrow=c(2,2))
hist(replicate(10^1, mean(runif(100))), col="orange", xlab = "mu", main = "10 Samples")
hist(replicate(10^2, mean(runif(100))), col="orange", xlab = "mu", main = "100 Samples")
hist(replicate(10^3, mean(runif(100))), col="orange", xlab = "mu", main = "1000 Samples")
hist(replicate(10^4, mean(runif(100))), col="orange", xlab = "mu", main = "10000 Samples")
dev.off()
cowplot::plot_grid(p1,p2,ncol = 2, labels = "AUTO")
par(mfrow=c(2,2))
hist(replicate(10^1, mean(rpois(100,3))), col="orange", xlab = "mu", main = "10 Samples")
hist(replicate(10^2, mean(rpois(100,3))), col="orange", xlab = "mu", main = "100 Samples")
hist(replicate(10^3, mean(rpois(100,3))), col="orange", xlab = "mu", main = "1000 Samples")
hist(replicate(10^4, mean(rpois(100,3))), col="orange", xlab = "mu", main = "10000 Samples")
par(mfrow=c(2,2))
hist(rpois(100,3),col="blue", xlab = "X", main = "Sample A")
hist(rpois(100,3),col="blue", xlab = "X", main = "Sample B")
hist(rpois(100,3),col="blue", xlab = "X", main = "Sample C")
hist(rpois(100,3),col="blue", xlab = "X", main = "Sample D")
x <- rnorm(100,0,1)
x
summary(x)
hist(x)
dev.off()
# draw 1000 observations from a normal dist with mean=10 and sd=2
x <- rnorm(1000,10,2)
summary(x)
hist(x)
# hypothesis test mu \neq 0
# calculate t-stat:
t <- (mean(x) - 0) / var(x)
t
print(T)
print(t)
n <- length(x)
2*pt(-abs(t), df=n-1)
p_value <- 2*pt(-abs(t), df=n-1)
p_value
t.test(x, 0)
help t.test
t.test?
?t.test
t.test(x, mu=0)
# hypothesis test mu \neq 0
## calculate t-stat:
t <- (mean(x) - 0) / var(x)
print(t)
t.test(x, mu=5)
t.test(x, mu=7)
t.test(x, mu=10)
t.test(x, mu=9)
t.test(x, mu=10)
t.test(x, mu=9)
(mean(x) - 10) / (sd(x) / sqrt(length(x)))
x
mean(x)
t.test(x, mu=9)
(mean(x) - 10) / (sd(x) / sqrt(length(x)))
(mean(x) - 9) / (sd(x) / sqrt(length(x)))
# hypothesis test mu \neq 0
## calculate t-stat:
n <- length(x)
(mean(x) - 9) / (sd(x) / sqrt(n))
# hypothesis test mu \neq 0
## calculate t-stat:
n <- length(x)
t <- (mean(x) - 9) / (sd(x) / sqrt(n))
print(t)
## calculate two-tailed p-value
p_value <- 2*pt(-abs(t), df=n-1) # all t-distributions are defined by degrees of freedom (df)
p_value
## replicate using the canned t-test
t.test(x, mu=9)
## replicate using the canned t-test
t.test(x, mu=10)
# hypothesis test mu \neq 0
## calculate t-stat:
n <- length(x)
t <- (mean(x) - 10) / (sd(x) / sqrt(n))
print(t)
## calculate two-tailed p-value
p_value <- 2*pt(-abs(t), df=n-1) # all t-distributions are defined by degrees of freedom (df)
p_value
data()
data("diamonds")
head(diamonds)
plot(diamonds$carat, diamonds$price)
library(tidyverse)
library(cowplot)
library(latex2exp)
data()
df <- readstata13::read.dta13("~/Desktop/auto.dta")
head(df)
write.csv(df, "auto.csv")
write.csv(df, "~/Desktop/auto.csv")
pwd
getwd()
setwd("~/Google Drive/boston_college_gdrive/behavioral_econ/github_org/be_bc_f19/R/R-intro/")
list.files()
# regression --------------------------------------------------------------
df <- read.csv("auto.csv")
head(df)
# single regression: Price(weight)
m1 <- lm(price~weight, data=df)
m1
summary(m1)
# recreate the hypothesis test by hand
# t-stat:
n <- nrow(df)
t <- (mean(df$weight) - 0) / (sd(df$weight) / sqrt(n))
t
t <- (2.0441 - 0) / (sd(df$weight) / sqrt(n))
t
t <- (2.0441 - 0) / 0.3768
t
# recreate the hypothesis test by hand
# t-stat is just beta/standard error:
t <- m1$coefficients[1]
t
# recreate the hypothesis test by hand
# t-stat is just beta/standard error:
t <- m1$coefficients[2]
t
# recreate the hypothesis test by hand
# t-stat is just beta/standard error:
t <- m1$coefficients[2] / coef(summary(m1))[, 2]
t
# recreate the hypothesis test by hand
# t-stat is just beta/standard error:
t <- m1$coefficients[2] / coef(summary(m1))[, 2][1]
t
summary(m1)
# recreate the hypothesis test by hand
# t-stat is just beta/standard error:
t <- 2.0441 / 0.3768
p <- 2*pt(-abs(t), df=nrow(df)-ncol(df))
# recreate the hypothesis test by hand
# t-stat is just beta/standard error:
t <- 2.0441 / 0.3768
p <- 2*pt(-abs(t), df=nrow(df)-ncol(df))
p
t
p <-
2*pt(-abs(t), df=72)
2*pt(-abs(t), df=72)
nrow(df)
nrow(df) - ncol(df)
p
print(t,p)
cat("t-value:"  t)
print(paste0("t-value: ", t))
print(paste0("p-value: ", p))
# multiple regression: Price(weight, foreign)
## hypothesis test: weight has an effect on price, controling for the effect of car origin (foreign)
table(df$foreign)
class(df$foreign)
levels(df$foreign)
m2 <-lm(price~weight+foreign, data=df)
summary(m2)
df <- df %>%
group_by(foreign) %>%
mutate(weight_by_origin = mean(weight))
# 2. create a variable that subtracts `weight`` from `weight_by_origin`
df$weight_no_origin <- df$weight - df$weight_by_origin
# 3. Now run a regression on price and our new variable:
summary(lm(price~weight_no_origin, data=df))
# 3. Now run a regression on price and our new variable:
lm(price~weight_no_origin, data=df)
# tidyverse data
data("mpg")
df <- mpg
# basic commands to plot data (qplot stands for "quick plot")
qplot(cty, data = df) # histogram
qplot(cty, hwy, data = df) # scatter plot
qplot(cty, hwy, data = df) # scatter plot
qplot(cty, hwy, data = df, facets = ~year) # scatter plot with one-way faceting
qplot(cty, hwy, data = df, facets = year~class) # scatter plot with two-way faceting
rpois(100,3
)
# sample from a poisson distribution with rate parameter 3
qplot(rpois(100,3))
# sample from a poisson distribution with rate parameter 3
qplot(rpois(100,3),col="blue")
# sample from a poisson distribution with rate parameter 3
qplot(rpois(100,3),fill="blue")
# sample from a poisson distribution with rate parameter 3
qplot(rpois(100,3),colour="blue")
# sample from a poisson distribution with rate parameter 3
qplot(rpois(100,3))
# sample from a poisson distribution with rate parameter 3
qplot(rpois(100,3))
# sample from a poisson distribution with rate parameter 3
qplot(rpois(100,3))
par(mfrow=c(2,2))
qplot(rpois(100,3))
qplot(rpois(100,3))
qplot(rpois(100,3))
qplot(rpois(100,3))
dev.off()
par(mfrow=c(2,2))
qplot(rpois(100,3))
qplot(rpois(100,3))
qplot(rpois(100,3))
qplot(rpois(100,3))
?dt
curve(dt(x, 30), from = -5, to = 5)
dev.off
dev.off()
curve(dt(x, 30), from = -5, to = 5)
# draw 1000 observations from a normal dist with mean=10 and sd=2
x <- rnorm(1000,10,2)
curve(dt(x, n-1), from = -5, to = 5)
# hypothesis test mu \neq 0
## calculate t-stat:
n <- length(x)
t <- (mean(x) - 10) / (sd(x) / sqrt(n))
?integrate
integrate(f = dt(x,n-1),lower = t, upper = Inf)
integrate(function(x) dt(x,n-1),lower = t, upper = Inf)
# hypothesis test mu \neq 0
## calculate t-stat:
n <- length(x)
t <- (mean(x) - 10) / (sd(x) / sqrt(n))
print(t)
## calculate two-tailed p-value
p_value <- 2*pt(-abs(t), df=n-1) # all t-distributions are defined by degrees of freedom (df)
p_value
2*0.221259
## can also integrate the t-distribution:
2*integrate(function(x) dt(x,n-1),lower = t, upper = Inf)
## can also integrate the t-distribution:
2*integrate(function(x) dt(x,n-1),lower = t, upper = Inf)
## can also integrate the t-distribution:
2*integrate(function(x) dt(x,n-1),lower = t, upper = Inf)[1]
integrate(function(x) dt(x,n-1),lower = t, upper = Inf)
class(integrate(function(x) dt(x,n-1),lower = t, upper = Inf))
integrate(function(x) dt(x,n-1),lower = t, upper = Inf)[1]
integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value
2*integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value
H0 <- 10
t <- (mean(x) - H0) / (sd(x) / sqrt(n))
print(t)
## calculate two-tailed p-value
p_value <- 2*pt(-abs(t), df=n-1) # all t-distributions are defined by degrees of freedom (df)
p_value
## can also integrate the t-distribution:
2*integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5)
## can also integrate the t-distribution:
ggplot(data.frame(x=c(0, 10)), aes(x)) + stat_function(fun=sin)
## can also integrate the t-distribution:
ggplot(data.frame(x=c(0, 10)), aes(x)) + stat_function(fun=dt)
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5)
abline(t)
abline(x=t)
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5)
abline(v=2, col="blue")
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5)
abline(v=t, col="blue")
abline(v=-t, col="blue")
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5,fill="blue")
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5)
abline(v=t, col="blue")
abline(v=-t, col="blue")
integrate(function(x) dt(x,n-1),lower = -Inf, upper = Inf)$value
H0 <- 9
t <- (mean(x) - H0) / (sd(x) / sqrt(n))
print(t)
## calculate two-tailed p-value
p_value <- 2*pt(-abs(t), df=n-1) # all t-distributions are defined by degrees of freedom (df)
p_value
print(p_value)
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5)
abline(v=t, col="blue")
abline(v=-t, col="blue")
t
2*integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value # integrate from t-stat to infinity (then times 2 since distribution is symmetric)
integrate(function(x) dt(x,n-1),lower = -Inf, upper = Inf)$value # sanity check: total area = 1
## replicate using the canned t-test
t.test(x, mu=9)
# draw 100 observations from a normal dist with mean=10 and sd=2
x <- rnorm(100,10,2)
summary(x)
# draw 100 observations from a normal dist with mean=10 and sd=2
x <- rnorm(100,10,2)
summary(x)
# hypothesis test mu \neq 10
## calculate t-stat:
n <- length(x)
H0 <- 9
t <- (mean(x) - H0) / (sd(x) / sqrt(n))
print(t)
## calculate two-tailed p-value
p_value <- 2*pt(-abs(t), df=n-1) # all t-distributions are defined by degrees of freedom (df)
print(p_value)
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5)
abline(v=t, col="blue")
abline(v=-t, col="blue")
2*integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value # integrate from t-stat to infinity (then times 2 since distribution is symmetric)
integrate(function(x) dt(x,n-1),lower = -Inf, upper = Inf)$value # sanity check: total area = 1
## replicate using the canned t-test
t.test(x, mu=9)
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5) ## visualize the t-distribution for our degrees of freedom
abline(t, col="blue") # t-stat (positive)
?shapiro.test
# draw 100 observations from a normal dist with mean=10 and sd=2
x <- rnorm(100,10,2)
summary(x)
hist(x)
# hypothesis test mu \neq 10 (\neq is LaTeX for "not equal to")
## calculate t-stat:
n <- length(x)
H0 <- 10
t <- (mean(x) - H0) / (sd(x) / sqrt(n))
print(t)
# draw 100 observations from a normal dist with mean=10 and sd=2
x <- rnorm(100,10,2)
summary(x)
hist(x)
# hypothesis test mu \neq 10 (\neq is LaTeX for "not equal to")
## calculate t-stat:
n <- length(x)
H0 <- 10
t <- (mean(x) - H0) / (sd(x) / sqrt(n))
print(t)
## calculate two-tailed p-value
p_value <- 2*pt(-abs(t), df=n-1) # all t-distributions are defined by degrees of freedom (df)
print(p_value)
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5) ## visualize the t-distribution for our degrees of freedom
abline(v=t, col="blue") # t-stat (positive)
abline(v=-t, col="blue") # t-stat (negative)
integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value # integrate from t-stat to infinity (then times 2 since distribution is symmetric)
integrate(function(x) dt(x,n-1),lower = -Inf, upper = Inf)$value # sanity check: total area = 1
## replicate using the canned t-test
t.test(x, mu=10)
2*integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value # integrate from t-stat to infinity (then times 2 since distribution is symmetric)
integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value # integrate from t-stat to infinity (then times 2 since distribution is symmetric)
integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value
H0 <- 0
t <- (mean(x) - H0) / (sd(x) / sqrt(n))
print(t)
integrate(function(x) dt(x,n-1),lower = t, upper = Inf)$value # integrate from t-stat to infinity (then times 2 since distribution is symmetric)
## replicate using the canned t-test
t.test(x, mu=10)
## replicate using the canned t-test
t.test(x, mu=0)
H0 <- 10
t <- (mean(x) - H0) / (sd(x) / sqrt(n))
print(t)
2*integrate(function(x) dt(x,n-1),lower = abs(t), upper = Inf)$value # integrate from t-stat to infinity (then times 2 since distribution is symmetric)
## calculate two-tailed p-value
p_value <- 2*pt(-abs(t), df=n-1) # all t-distributions are defined by degrees of freedom (df)
print(p_value)
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5) ## visualize the t-distribution for our degrees of freedom
abline(v=t, col="blue") # t-stat (positive)
abline(v=-t, col="blue") # t-stat (negative)
2*integrate(function(x) dt(x,n-1),lower = abs(t), upper = Inf)$value # integrate from t-stat to infinity (then times 2 since distribution is symmetric)
integrate(function(x) dt(x,n-1),lower = -Inf, upper = Inf)$value # sanity check: total area = 1
## replicate using the canned t-test
t.test(x, mu=10)
# draw 100 observations from a normal dist with mean=10 and sd=2
x <- rnorm(100,10,2)
summary(x)
hist(x)
# hypothesis test mu \neq 10 (\neq is LaTeX for "not equal to")
## calculate t-stat:
n <- length(x)
H0 <- 10
t <- (mean(x) - H0) / (sd(x) / sqrt(n))
print(t)
## calculate two-tailed p-value
p_value <- 2*pt(-abs(t), df=n-1) # all t-distributions are defined by degrees of freedom (df)
print(p_value)
## can also integrate the t-distribution:
curve(dt(x,n-1), from = -5, to = 5) ## visualize the t-distribution for our degrees of freedom
abline(v=t, col="blue") # t-stat (positive)
abline(v=-t, col="blue") # t-stat (negative)
2*integrate(function(x) dt(x,n-1),lower = abs(t), upper = Inf)$value # integrate from t-stat to infinity (then times 2 since distribution is symmetric)
integrate(function(x) dt(x,n-1),lower = -Inf, upper = Inf)$value # sanity check: total area = 1
## replicate using the canned t-test
t.test(x, mu=10)
